---
title: "null model accuracy assessment"
author: "MNSnyder"
date: "8/28/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(e1071)
library(muma)
```


Script to create a bootstrap null classification accuracy to compare with classification accuracy of actual treatments.

1. Subset to only control data

2. Combine all Control data 

3. Randomly select a peak for each RT for all the control data 

4. Do step 3. 5 times and call that control data

5. Do step 3. again 5 times  and call that exposure data

6. Run SVM-RFE on the 'null' control and 'null' exposure data

7. Repeat 1000x

8. Get a statistic (percentile/Z score?) to compare to your original results

Import data processed and retention time aligned with XCMS. 
Classes represent treatments.
1 = no pesticide, no predator
2 = pesticide, no predator
3 = no pesticide, predator
4 = pesticide, predator


```{r set up directories, echo=FALSE}
# to run script on different computers specify sys.info()[4] and
# specify path to model results folder and
# folder containing look up tables

# Tom's laptop
if(Sys.info()[4]=="LZ2626UTPURUCKE"){
  datadir<-path.expand("c:/git/PIP/") # path to git repo
}

# Tom's linux
if(Sys.info()[4]=="d2626ut7920d.rtpnc.epa.gov"){
  datadir<-path.expand("~/git/PIP/") # path to git repo
}

# Marcia's epa computer -> WORKS
if(Sys.info()[4]=="LZ2626XMSNYDE02"){
  datadir<-path.expand("D:/git_repo/PIP/") # path to git repo
}
```


```{r import aligned data}
# control vs. pesticide only
class <- read.csv(paste(datadir,"GCMS_data_XCMS/WorkDir_liver1/Preprocessing_Data_a/class.csv", sep=""), header =TRUE, sep=",")

ProcessedTable <- read.csv(paste(datadir,"GCMS_data_XCMS/WorkDir_liver1/Preprocessing_Data_a/ProcessedTable.csv", sep=""), header = TRUE, sep=",")

allliver<-cbind(class$V1, ProcessedTable)
allliver2<-allliver[order(class$V1),]
# drop classes 2 and 3
control_peaks<-allliver2[-11:-30,]
```

Create function to create null control and null exposure data sets all sampled from the 10 control samples. 

```{r randomly select a peak for each RT for all the control data}
# function to create a hypothetical liver sample by randomly selecting from a number of real samples in a dataframe

# row is a sample
# column is a peak
peak_picking<-function(peaks, number_of_peaks, number_of_samples){
  for (j in 1:number_of_peaks){
 row_x <- sample(1:number_of_samples, 1)
 selected_peak_value<-peaks[row_x,j]
 new_sample[j]<-selected_peak_value
  }
  return(new_sample)
}
```

Format data pre-processed (retention time aligned and scaled) data to create null control and exposure from control data. 
```{r create null data}
# run function 10x
# drop label and sample name columns
control_peaks2<-control_peaks[,-1:-2]
# get number of peaks for function
number_of_peaks2<-dim(control_peaks2)[2] #1584
# get number of samples for function
number_of_samples2<-dim(control_peaks2)[1] #10
new_sample<-NULL

cntrl1<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
cntrl2<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
cntrl3<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
cntrl4<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
cntrl5<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
exposure1<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
exposure2<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
exposure3<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
exposure4<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
exposure5<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)

class<-c(1,1,1,1,1,2,2,2,2,2)
# combine new control and exposure data into a dataframe for SVM-RFE
null_sample<-rbind.data.frame(cntrl1, cntrl2, cntrl3, cntrl4, cntrl5, exposure1, exposure2, exposure3, exposure4, exposure5)
null_sample<-cbind(null_sample, class)
# convert to dataframe
#null_sample2<-as.data.frame(null_sample)
# add key to treatment level to dataframe
#null_sample$class<-1
#null_sample$class[6:10]<-2
# change to factor
null_sample$class<-as.factor(null_sample$class)
```

Function that creates the RFE. 
```{r create feature ranking function}
#### create function for other R implementation of RFE for SVM ####
svmrfeFeatureRanking = function(x,y){
  n = ncol(x)
  survivingFeaturesIndexes = seq(1:n)
  featureRankedList = vector(length=n)
  rankedFeatureIndex = n
  while(length(survivingFeaturesIndexes)>0){
    #train the support vector machine
    svmModel = svm(x[, survivingFeaturesIndexes], y, cost = 6.4e9, gamma=1.0e-10, cachesize=500,
                   scale=F, type="C-classification", kernel="radial" )
    #compute the weight vector
    w = t(svmModel$coefs)%*%svmModel$SV
    #compute ranking criteria
    rankingCriteria = w * w
    #rank the features
    ranking = sort(rankingCriteria, index.return = TRUE)$ix
    #update feature ranked list
    featureRankedList[rankedFeatureIndex] = survivingFeaturesIndexes[ranking[1]]
    rankedFeatureIndex = rankedFeatureIndex - 1
    #eliminate the feature with smallest ranking criterion
    (survivingFeaturesIndexes = survivingFeaturesIndexes[-ranking[1]])
  }
  return (featureRankedList)
}
```

Apply RFE function to one set of null data. Uses the 70 best peaks. For the real data we used the top 70 ranked features.
```{r SVM RFE for one null and another null picked from control}
#prepare data for RFE
X<-null_sample[,-1585]  
Y<-null_sample$class
#RFE
featureRankedList <-svmrfeFeatureRanking(X,Y)
# maximum number of peaks to include
max<-70
#SVM w/ RFE
svmModel = svm(X[, featureRankedList[1:max]], Y, cost = 1e10, gamma=1.0e-10, kernel="radial", cross=3 )
svmModel 
summary(svmModel)
```

We get very high accuracy comparing differences between control and control with 70 peaks. To see how accuracy increases with number of ranked peaks did a bootstrapped accuracy for null control vs. null control w/ rfe.
```{r plot of number of peaks and accuracy}
no.features<-seq(1,10,by=1)
out.acc<-NULL
accuracy.vector<-NULL
for (j in seq_along(no.features)){
  for (i in 1:250){
    svmModel3 = svm(X[, featureRankedList[1:no.features[j]]], Y, cost = 1e10, kernel="radial", cross=3 )
    accuracy.vector[i]<-svmModel3$tot.accuracy
  }
  out.acc[j]<-mean(accuracy.vector)  
}
out.acc
acc4merge<-as.data.frame(cbind(no.features, out.acc))
View(acc4merge)
plot(acc4merge$no.features, acc4merge$out.acc, ylab="% Accuracy", xlab="Number of bins")
```
 
With this set of samples, it looks like it only takes the top 2 ranked peak to reach accuracy >90%.

######################################################################
BOOTSTRAPPING
Create function to create 100 different null data sets in an array-
* rows = samples 
* columns = peaks 
* matrices = sample
```{r create an array of null samples}
##### set up inputs for loop ######
no_null_samples<-15
# number of null sample sets to create
no.matrices<-no.features<-seq(1,no_null_samples,by=1)
# drop label and sample name columns
control_peaks2<-control_peaks[,-1:-2]
# size of full array 
no_peaks<-dim(control_peaks2)[2]
# get number of peaks for function
number_of_peaks2<-dim(control_peaks2)[2] #1584
# get number of samples for function
number_of_samples2<-dim(control_peaks2)[1] #10
# set up empty array
null.array <- array(data=NA, dim=c(number_of_samples2,no_peaks,length(no.matrices)))
# set up class vector
class<-c(1,1,1,1,1,2,2,2,2,2)
# set up new sample vector
new_sample<-NULL
##################################

for (k in seq_along(no.matrices)){

  cntrl1<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
  cntrl2<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
  cntrl3<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
  cntrl4<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
  cntrl5<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
  exposure1<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
  exposure2<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
  exposure3<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
  exposure4<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)
  exposure5<-peak_picking(control_peaks2, number_of_peaks2, number_of_samples2)

# combine new control and exposure data into a dataframe for SVM-RFE
null_sample<-rbind.data.frame(cntrl1, cntrl2, cntrl3, cntrl4, cntrl5, exposure1, exposure2, exposure3, exposure4, exposure5)
#null_sample<-cbind(null_sample, class)
# convert to factor
#null_sample$class<-as.factor(null_sample$class)
null.array[,,k]<-as.matrix(null_sample)
}
```

For each matrix in the array, RFE feature ranking then use SVM to classify using a maximum of 70 ranked peaks. Creates a histogram of 3 fold cross validation total accuracy values for each classification.

```{r analyze array of null samples}
# set up classes outside loop since they remain the same
class<-c(1,1,1,1,1,2,2,2,2,2)
class_df<-data.frame(class)
class_df$class<-as.factor(class_df$class)
Y<-class_df$class # use classes from above
# maximum number of ranked peaks to include
max<-70
# accuracy vector
null_acc<-NULL

for (m in 1:no_null_samples){
  null_temp<-as.data.frame(null.array[,,m])
  #prepare data for RFE
  X<-null_temp  
  #RFE
  featureRankedList <-svmrfeFeatureRanking(X,Y)
  #SVM w/ RFE
  svmModel = svm(X[, featureRankedList[1:max]], Y, cost = 1e10, gamma=1.0e-10, kernel="radial", cross=3 )
  null_acc[m]<-svmModel$tot.accuracy
  }

hist(null_acc)

```



